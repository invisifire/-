## 前言

此部分介绍为传统树形机器学习方法，对于结构化数据以及样本量少的数据集，传统方法的表现会优于深度神经网络，机器学习中有大量的超参数（人工填写的固定值）对于模型的影响较大，根据不同数据调整超参数是主要的任务，因此有autoML自动机器学习算法用来自动调节超参数。（注：树形机器学习方法对于多字段（大于30）提取表现远不如深度神经网络。）

## 决策树

 [微痛学习 决策树 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/360060513) 

重点决策树是建立特征对应分类的树形结构，通过特征值的信息增益熵来判定是否需要分支。

## GBM

** [系统梳理 Gradient Boosting Machine - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/361036526) **本文为文章简化改写如有不懂查看原文

 梯度提升机（Gradient Boosting Machine，GBM）是 Boosting 的一种实现方式。  **Boosting 的思想**是：n 个弱学习器 -> 强学习器。它没有限定算法特点，能把弱变强即可，但大多数 Boosting 算法都会螺旋迭代式地训练弱学习器，然后将结果加起来作为最终结果。形象点来说就是这样： ![img](https://pic2.zhimg.com/80/v2-32f80c4324d917bc3decbf12e3ef6005_1440w.webp) 那么什么是 那么什么是弱学习器，什么是强学习器？**弱学习器**就是比随即分类稍好一点，比如随即分类正确率为 50%，错误率为 50%，那么弱学习器正确率就是刚刚超过 50% 一点，比如 55%，而**强学习器**则是正确率很高很高，比如 90%，如下图： ![img](https://pic1.zhimg.com/80/v2-05f2b5a3bc8909627b8aaa4ea8a79278_1440w.webp)

GBM通过 **缩减（shrinkage）**的方式来形成多个弱学习器。缩减的主要思想是对于第一个弱学习器F(x) 提升拟合效果的方法就是训练一个新的学习器h(x)去学习F(x)与真实值之间的差距，用F(x)+h(x)表示新的预测值。

![img](https://pic2.zhimg.com/80/v2-95af5837c5407a39c42be343ab958dad_1440w.webp)

设F(x)+p* h(x)为新的拟合函数寻找使loss值最小的p，这里的loss是F(x)+p* h(x)与真实值y之间loss函数值。至此完成一次缩减操作。

通过循环N缩减操作最终得到GBM学习器，但实践证明这样的GBM学习器泛化性不好，容易过拟合，因此通常我们需要添加超参数V代表学习率，将一次缩减的函数改为F(x)+v* p* h(x)

### GBM 个人总结

GBM是一种机器学习的优化框架，并未局限弱学习器的算法（一般使用决策树里的cart模型），必须结合其他学习器使用。同时这种算法框架也可以使用深度神经网络作为学习器。主要思想为**Boosting 和shrinkage**

## XGBoost







## DeepGBM







